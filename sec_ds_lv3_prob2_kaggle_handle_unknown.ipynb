{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa73290",
   "metadata": {},
   "source": [
    "## 문제 6\n",
    "\n",
    "**Kaggle 형** train_prob.csv로 문제 target을 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 target 예측하여 다음과 같은 형식의 answer6.csv를 만들어라.\n",
    "\n",
    "id, target\n",
    "\n",
    "0, 6.9\n",
    "\n",
    "5, 7.8\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "**평가지표**\n",
    "\n",
    "$RMSE(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y_i-\\hat{y_i})^2}$\n",
    "\n",
    "**강사: 멀티캠퍼스 강선구(sunku0316.kang@multicampus.com, sun9sun9@gmail.com)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8af540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Oct 17 2019, 06:10:02) \n",
      "[GCC 8.3.0]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3790bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_test = pd.read_csv('test_prob.csv', index_col='id')\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4e351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 {'B': 'C'} [83634, 147361, 9005]\n",
      "cat4 {'A': 'B', 'D': 'B'} [239397, 603]\n",
      "cat6 {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'} [234203, 5145, 652]\n",
      "cat7 {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'} [4606, 19784, 214027, 1583]\n",
      "cat8 {'B': 'G', 'F': 'E'} [30338, 96743, 2953, 76085, 33881]\n",
      "cat9 {'C': 'H', 'D': 'B', 'E': 'L'} [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968]\n"
     ]
    }
   ],
   "source": [
    "# 처리 과정에 필요하 내용들을 list 형태로 구성합니다.\n",
    "repl_list = [\n",
    "    ('cat3', {'B': 'C'}, [83634, 147361, 9005]),\n",
    "    ('cat4', {'A': 'B', 'D': 'B'}, [239397, 603]),\n",
    "    ('cat6', {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'}, [234203, 5145, 652]),\n",
    "    ('cat7', {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'}, [4606, 19784, 214027, 1583]),\n",
    "    ('cat8', {'B': 'G', 'F': 'E'}, [30338, 96743, 2953, 76085, 33881]),\n",
    "    ('cat9', {'C': 'H', 'D': 'B', 'E': 'L'}, [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968])\n",
    "]\n",
    "# 반복문 처리 내용들을 수행합니다.\n",
    "for v, d, cnts in repl_list:\n",
    "    print(v, d, cnts)\n",
    "    # 치환후 내용을 s_repl에 저장합니다\n",
    "    s_repl = df_train[v].replace(d)\n",
    "    # 치환결과를 확인합니다.\n",
    "    if (s_repl.nunique() != len(cnts)) or ((s_repl.value_counts().sort_index() != cnts).any()):\n",
    "        print(s_repl.value_counts())\n",
    "        break\n",
    "    df_train[v] = s_repl\n",
    "    if v != 'cat9': # test에 cat9가 train에 등장하지 않는 케이스를 만듭니다.\n",
    "        df_test[v] = df_test[v].replace(d)\n",
    "    \n",
    "cat_cols = ['cat{}'.format(i) for i in range(10)]\n",
    "cont_cols = ['cont{}'.format(i) for i in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d062adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "\n",
    "X_all = df_test.columns.tolist()\n",
    "df_train['targetA'] = df_train['target'] <= 7.45\n",
    "\n",
    "if not os.path.isfile('targetA_train.csv'):\n",
    "    \n",
    "    df_train_clf = df_train.assign(\n",
    "        prob_A = 1 - norm.cdf(df_train['target'], loc=6.769, scale=0.616),\n",
    "        prob_B = norm.cdf(df_train['target'], loc=8.123, scale=0.527)\n",
    "    ).query('prob_B < 0.01 or prob_A < 0.01').copy()\n",
    "    \n",
    "    clf_xgb = make_pipeline( \n",
    "        ColumnTransformer([\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "            ('pt', 'passthrough', cont_cols)\n",
    "        ]),\n",
    "        xgb.XGBClassifier(\n",
    "            max_depth = 2, # 트리의 최대 깊이 2\n",
    "            reg_alpha = 0.1, # L1 규제 0.1\n",
    "            reg_lambda = 0.1, # L2 규제 0.1\n",
    "            colsample_bytree=0.25, # 트리 당 컬럼 샘플링 비율 0.25\n",
    "            n_estimators=500, # 트리의 수 500\n",
    "            random_state=123, # random_state 123\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    clf_xgb.fit(df_train_clf[X_all], df_train_clf['targetA'])\n",
    "    df_targetA_train = pd.DataFrame({'targetA_prob': clf_xgb.predict_proba(df_train[X_all])[:, 1]}, index=df_train.index)\n",
    "    \n",
    "    targetA_prob_cv = cross_val_predict(clf_xgb, df_train_clf[X_all], df_train_clf['targetA'], cv=5, method='predict_proba')\n",
    "    df_targetA_train.loc[df_targetA_train.index.isin(df_train_clf.index), 'targetA_prob'] = targetA_prob_cv[:, 1]\n",
    "    \n",
    "    df_targetA_train.to_csv('targetA_train.csv')\n",
    "    df_targetA_test = pd.DataFrame({'targetA_prob': clf_xgb.predict_proba(df_test[X_all])[:, 1]}, index=df_test.index)\n",
    "    df_targetA_test.to_csv('targetA_test.csv')\n",
    "else:\n",
    "    df_targetA_train = pd.read_csv('targetA_train.csv', index_col='id')\n",
    "    df_targetA_test = pd.read_csv('targetA_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fdc202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['targetA_prob'] = df_targetA_train['targetA_prob']\n",
    "df_test['targetA_prob'] = df_targetA_test['targetA_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441a6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [i for i in np.arange(0, 1.01, 0.01)]\n",
    "for i in cont_cols:\n",
    "    q_val = df_train[i].quantile(q)\n",
    "    q_val.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "    q_cut = pd.cut(df_train[i], bins=q_val)\n",
    "    q_mean = df_train.groupby(q_cut)['target'].mean()\n",
    "    df_train[i + '_q'] = q_cut.map(q_mean).astype('float')\n",
    "    df_test[i + '_q'] = pd.cut(df_test[i], bins=q_val).map(q_mean).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc3911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "\n",
    "s_hist = []\n",
    "cv = KFold(n_splits=5, random_state=123)\n",
    "ss = ShuffleSplit(n_splits=1, train_size=0.8, random_state=123)\n",
    "\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')\n",
    "X_all = df_test.columns.tolist()  + ['targetA_prob']\n",
    "\n",
    "cat_cols = ['cat{}'.format(i) for i in range(10)]\n",
    "cont_cols = ['cont{}'.format(i) for i in range(14)]\n",
    "cont_q_cols = ['cont{}_q'.format(i) for i in range(14)]\n",
    "\n",
    "q = [i for i in np.arange(0, 1.01, 0.01)]\n",
    "def eval_model(model_name, model, sp):\n",
    "    score_train, score_valid = list(), list()\n",
    "    for train_idx, valid_idx in sp.split(df_train):\n",
    "        df_cv_train, df_valid = df_train.iloc[train_idx].copy(), df_train.iloc[valid_idx].copy()\n",
    "        for i in cont_cols:\n",
    "            q_val =  df_cv_train[i].quantile(q)\n",
    "            q_val.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "            q_cut = pd.cut(df_cv_train[i], bins=q_val)\n",
    "            q_mean = df_cv_train.groupby(q_cut)['target'].mean()\n",
    "            df_cv_train[i + '_q'] = q_cut.map(q_mean).astype('float')\n",
    "            df_valid[i + '_q'] = pd.cut(df_valid[i], bins=q_val).map(q_mean).astype('float')\n",
    "        model.fit(df_cv_train[X_all], df_cv_train['target'])\n",
    "        score_valid.append((mean_squared_error(df_valid['target'], model.predict(df_valid[X_all]))) ** 0.5)\n",
    "        score_train.append((mean_squared_error(df_cv_train['target'], model.predict(df_cv_train[X_all]))) ** 0.5)\n",
    "        \n",
    "    output = 'Valid: {:.5f}±{:.5f},  V.Train: {:.5f}±{:.5f}'.format( \n",
    "            np.mean(score_valid), np.std(score_valid),\n",
    "            np.mean(score_train), np.std(score_train),\n",
    "        )\n",
    "    print(output)\n",
    "    s_hist.append(pd.Series([model_name, output, np.mean(score_valid)], index=['model name', 'result', 'score']))\n",
    "    df_result = pd.DataFrame(s_hist)\n",
    "    display(df_result.groupby('model name').last())\n",
    "    display(df_result.loc[df_result['score'].idxmin()])\n",
    "\n",
    "def select_model(model):\n",
    "    model.fit(df_train[X_all], df_train['target'])\n",
    "    prd = model.predict(df_test[X_all])\n",
    "    pd.DataFrame({\n",
    "        'id': df_test.index.values,\n",
    "        'target': prd\n",
    "    }).to_csv('answer6.csv', index = None)\n",
    "    return prd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c265043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 0.86325±0.00296,  V.Train: 0.86303±0.00074\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>baseline</td>\n",
       "      <td>Valid: 0.86325±0.00296,  V.Train: 0.86303±0.00074</td>\n",
       "      <td>0.863247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       result     score\n",
       "model name                                                             \n",
       "baseline    Valid: 0.86325±0.00296,  V.Train: 0.86303±0.00074  0.863247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model name                                             baseline\n",
       "result        Valid: 0.86325±0.00295,  V.Train: 0.86300±0.00073\n",
       "score                                                  0.863246\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'), cat_cols), # drop과 handle_unknown = 'ignore'를 동시에 쓸수 없어, drop을 포기합니다.\n",
    "    ('std', StandardScaler(), cont_cols)\n",
    "])\n",
    "\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "\n",
    "eval_model('baseline', reg_lr, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af98237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 채점 결과: 534085184.9390879\n"
     ]
    }
   ],
   "source": [
    "prd = select_model(reg_lr)\n",
    "print(\"baseline 채점 결과:\",  mean_squared_error(df_ans['target'], prd) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38b60db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.79874229e+09, -5.79874229e+09,  3.19972035e+08,  3.19972035e+08,\n",
       "       -5.44993806e+09, -5.44993806e+09,  5.35890416e+09,  5.35890416e+09,\n",
       "        5.35890416e+09,  3.66690782e+11,  3.66690782e+11, -5.81229216e+10,\n",
       "       -5.81229216e+10, -5.81229216e+10, -5.81229216e+10,  5.72112918e+09,\n",
       "        5.72112918e+09,  5.72112918e+09,  1.56031518e+10,  1.56031518e+10,\n",
       "        1.56031518e+10,  1.56031518e+10,  1.77241212e+10,  1.77241212e+10,\n",
       "        1.77241212e+10,  1.77241212e+10,  1.77241212e+10, -1.47188070e+10,\n",
       "       -1.47188070e+10, -1.47188070e+10, -1.47188070e+10, -1.47188070e+10,\n",
       "       -1.47188070e+10, -1.47188070e+10, -1.47188070e+10, -1.47188070e+10,\n",
       "       -1.47188070e+10, -1.47188070e+10, -1.47188070e+10, -5.82580566e-02,\n",
       "        3.44848633e-02,  2.14004517e-03, -5.58471680e-03, -5.43212891e-03,\n",
       "       -5.46493530e-02,  2.36053467e-02,  1.55181885e-02,  6.80541992e-02,\n",
       "        2.73017883e-02, -2.11868286e-02,  5.16967773e-02,  1.57165527e-02,\n",
       "       -5.84411621e-03])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 상태를 봅니다.\n",
    "# 완전한 다중공선성에 의해 굉장히 불안정한 회귀계수가 만들어집니다.\n",
    "# 이로 인해 등장하지 않은 케이스에서 이상한 예측 값이 만들어저 굉장히 높은 RMSE를 얻게 된 것입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown = 'ignore'), cat_cols),\n",
    "    ('std', StandardScaler(), cont_cols)\n",
    "])\n",
    "\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "reg_lr.fit(df_train[X_all], df_train['target'])\n",
    "reg_lr[1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e65dfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat0           {}\n",
       "cat1           {}\n",
       "cat2           {}\n",
       "cat3           {}\n",
       "cat4           {}\n",
       "cat5           {}\n",
       "cat6           {}\n",
       "cat7           {}\n",
       "cat8           {}\n",
       "cat9    {E, C, D}\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원인을 탐색합니다.\n",
    "\n",
    "# 차집합 연산을 이용하여 등장하지 않은 범주값을 뽑아냅니다.\n",
    "pd.concat([\n",
    "    df_train[cat_cols].apply(set, axis = 0).rename('train'),\n",
    "    df_test[cat_cols].apply(set, axis = 0).rename('test')\n",
    "], axis=1).apply(\n",
    "    lambda x: x['test'] - x['train'], axis =1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136df0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['cat9'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "673862f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조치를 합니다.\n",
    "# 미등장 범주값을 최빈값으로 치환\n",
    "m = df_train['cat9'].mode()[0]\n",
    "df_test['cat9'] = df_test['cat9'].replace({'E': m, 'C': m, 'D': m})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c29b115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat0    {}\n",
       "cat1    {}\n",
       "cat2    {}\n",
       "cat3    {}\n",
       "cat4    {}\n",
       "cat5    {}\n",
       "cat6    {}\n",
       "cat7    {}\n",
       "cat8    {}\n",
       "cat9    {}\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해결 되었는지 확인합니다.\n",
    "pd.concat([\n",
    "    df_train[cat_cols].apply(set, axis = 0).rename('train'),\n",
    "    df_test[cat_cols].apply(set, axis = 0).rename('test')\n",
    "], axis=1).apply(\n",
    "    lambda x: x['test'] - x['train'], axis =1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e86bdc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 0.86325±0.00295,  V.Train: 0.86300±0.00073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>baseline</td>\n",
       "      <td>Valid: 0.86325±0.00295,  V.Train: 0.86300±0.00073</td>\n",
       "      <td>0.863246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       result     score\n",
       "model name                                                             \n",
       "baseline    Valid: 0.86325±0.00295,  V.Train: 0.86300±0.00073  0.863246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model name                                             baseline\n",
       "result        Valid: 0.86325±0.00295,  V.Train: 0.86300±0.00073\n",
       "score                                                  0.863246\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#  drop ='first'사용합니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), cat_cols),\n",
    "    ('std', StandardScaler(), cont_cols)\n",
    "])\n",
    "\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "eval_model('baseline', reg_lr, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e8ee5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14737833,  0.16983335,  0.24147158,  0.10693804,  0.03994362,\n",
       "        0.15713566,  0.03681214, -0.17486971,  0.03074087,  0.21519861,\n",
       "        0.36870383, -0.00597853, -0.05547379, -0.05870304, -0.00092302,\n",
       "        0.05854559,  0.07181603, -0.10018803,  0.03508515,  0.13365193,\n",
       "        0.1647826 ,  0.08022279, -0.00404722,  0.02865399,  0.09003857,\n",
       "        0.21092791,  0.09276305,  0.09655687,  0.07017521, -0.05824285,\n",
       "        0.03454985,  0.00214071, -0.00554697, -0.00543278, -0.05465513,\n",
       "        0.02359775,  0.01552286,  0.06808225,  0.0272966 , -0.02116763,\n",
       "        0.05174013,  0.01574269, -0.0058063 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델의 상태를 봅니다.\n",
    "# 등장하지 않은 범주값은 없으니, 에러가 해결됩니다.\n",
    "# 지나치게 회귀 계수가 커졌던 문제가 해결 됩니다.\n",
    "\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "reg_lr.fit(df_train[X_all], df_train['target'])\n",
    "reg_lr[1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a7753ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 채점 결과: 0.8657268588416209\n"
     ]
    }
   ],
   "source": [
    "prd = select_model(reg_lr)\n",
    "print(\"baseline 채점 결과:\",  mean_squared_error(df_ans['target'], prd) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e86bfe6",
   "metadata": {},
   "source": [
    "**선형회귀**, **로지스틱회귀** 등 모수적 모델에서는 완전한 다중공선성은 모델에 큰 불안정을 야기시킬 수 있습니다. \n",
    "\n",
    "따라서 drop='first'등 범주를 하나 제거하여 공선성을 없애는 작업은 반드시 해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31593b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
